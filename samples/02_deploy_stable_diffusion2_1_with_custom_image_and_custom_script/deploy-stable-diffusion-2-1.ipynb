{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cac437b",
   "metadata": {},
   "source": [
    "# Stable diffusion 2.1 - Sagemaker endpoint, Custom inference script, and Custom ECR image\n",
    "### Deploy Stable Diffusion Models with Full Control to a SageMaker Endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81428eab",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Development Environment and Permissions](#Development-Environment-and-Permissions)\n",
    "3. [Custom inference script](#custom-inference-script-creation)\n",
    "4. [Create model and deploy](#creation-of-the-hugging-face-model-and-deploy)\n",
    "5. [Test endpoint](#testing-the-endpoint)\n",
    "6. [Conclusion](#conclusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "263bd74b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to our SageMaker endpoint example, where we will deploy a Stable Diffusion 2.1 base model. In this notebook, we will create a new inference script and refer to the [extending-image-notebook](../01_extending_aws_dlc_images/extending-image.ipynb) for guidance on creating a custom ECR image. That notebook provides detailed instructions on extending AWS DLC images and incorporating your custom image into the deployment process. Additionally, if you prefer to use an AWS DLC image, make sure to include a requirements.txt file with the necessary Python libraries for running the Stable Diffusion model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "660b11a8-b42d-4ca9-adfb-07a9b95ee50a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Development Environment and Permissions\n",
    "\n",
    "## Installing Required Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6c8d5-23e0-49e4-b554-28cbc671a743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker==2.116.0\" \"huggingface_hub==0.10.1\" --upgrade --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73d1c81d",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2300cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n",
    "# Check if the \"code\" directory exists, and create it if it doesn't\n",
    "code_dir = \"code\"\n",
    "if not os.path.exists(code_dir):\n",
    "    os.makedirs(code_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fca23dd0",
   "metadata": {},
   "source": [
    "## Retrieving Image URI and Model URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b44e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'model-txt2img-stabilityai-stable-diffusion-v2-1-base'\n",
    "model_version = \"*\"\n",
    "from sagemaker import model_uris\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "endpoint_name = name_from_base(\"stable-diffusion-v2-1-base\")\n",
    "\n",
    "# Retrieve the model URI, which includes the pre-trained model, parameters, and inference scripts.\n",
    "# This URI encompasses all necessary dependencies and scripts for model loading and inference handling.\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "print(model_uri)\n",
    "\n",
    "# Alternatively, you can use your own stored model's S3 URI.\n",
    "s3_model_uri = 's3://sagemaker-us-west-2-499172972132/stable-diffusion-v2-1/model.tar.gz'\n",
    "print(s3_model_uri)\n",
    "\n",
    "aws_DLC_image = '763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04'\n",
    "custom_ecr_image = 'xxxxxxxxxx.dkr.ecr.us-west-2.amazonaws.com/pytorch-extending-deepspeed-stable-diffusion-v2-1-base'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dff72d7",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53bf0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "  base64_image = base64.b64decode(image_string)\n",
    "  buffer = BytesIO(base64_image)\n",
    "  return Image.open(buffer)\n",
    "\n",
    "# display PIL images as grid\n",
    "def display_images(images=None,columns=3, width=100, height=100):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10edf97d-2751-41a7-9d2f-dd8cba8f2c1f",
   "metadata": {},
   "source": [
    "# Custom Inference Script Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22537ff5-c48b-40e4-9bb2-f5585407e478",
   "metadata": {},
   "source": [
    "### Inference script extension:\n",
    "We have expanded the base inference script to include support for additional functionalities such as text-to-image, image-to-image, and text-to-vector transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c695fe0-9192-46da-84be-8d33b8d94e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "import base64\n",
    "import torch\n",
    "from io import BytesIO\n",
    "import json\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, StableDiffusionImg2ImgPipeline\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "\n",
    "    device = \"cuda\"\n",
    "    image2image_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        model_dir,\n",
    "        torch_dtype=torch.float16,\n",
    "    ).to(device)\n",
    "\n",
    "    # Load stable diffusion and move it to the GPU\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_dir, torch_dtype=torch.float16)\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "\n",
    "    return { \"text2image\": pipe, \"image2image\": image2image_pipe }\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "    device = \"cuda\"\n",
    "    # get prompt & parameters\n",
    "    prompt = data.pop(\"inputs\", data)\n",
    "    # set valid HP for stable diffusion\n",
    "    num_inference_steps = max(min(data.pop(\"num_inference_steps\", 25), 100), 0)\n",
    "    guidance_scale = data.pop(\"guidance_scale\", 7.5)\n",
    "    strength = data.pop(\"strength\", 0.8)\n",
    "    num_images_per_prompt = data.pop(\"num_images_per_prompt\", 1)\n",
    "    negative_prompt = data.pop(\"negative_prompt\", None)\n",
    "\n",
    "    width = max(min(data.pop(\"width\", 512), 1024), 64)\n",
    "    height = max(min(data.pop(\"height\", 512), 1024), 64)\n",
    "    width = (width // 8) * 8\n",
    "    height = (height // 8) * 8\n",
    "\n",
    "    # get mode (text2image, text2vector, image2image)\n",
    "    mode = data.pop(\"mode\", data)\n",
    "    init_image = data.pop(\"image\", None)\n",
    "\n",
    "\n",
    "    seed = data.pop(\"seed\", None)\n",
    "    latents = None\n",
    "    seeds = []\n",
    "\n",
    "    generator = torch.Generator(device=device)\n",
    "    if mode == 'text2image':\n",
    "        if seed:\n",
    "            generator.manual_seed(seed)\n",
    "            latents = torch.randn(\n",
    "                (1, pipe[mode].unet.in_channels, height // 8, width // 8),\n",
    "                generator = generator,\n",
    "                device = device\n",
    "            )\n",
    "            #we set the amount of images to 1, otherwise we're generating x times the same image.\n",
    "            num_images_per_prompt = 1\n",
    "        else:\n",
    "            for _ in range(num_images_per_prompt):\n",
    "                # Get a new random seed, store it and use it as the generator state\n",
    "                _seed = generator.seed()\n",
    "                seeds.append(_seed)\n",
    "                generator = generator.manual_seed(_seed)\n",
    "\n",
    "                image_latents = torch.randn(\n",
    "                    (1, pipe[mode].unet.in_channels, height // 8, width // 8),\n",
    "                    generator = generator,\n",
    "                    device = device\n",
    "                )\n",
    "                latents = image_latents if latents is None else torch.cat((latents, image_latents))\n",
    "\n",
    "        # run generation with parameters\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            generated_images = pipe['text2image'](\n",
    "                [prompt] * num_images_per_prompt,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                guidance_scale=guidance_scale,\n",
    "                # num_images_per_prompt=num_images_per_prompt,\n",
    "                negative_prompt=[negative_prompt] * num_images_per_prompt if negative_prompt else None,\n",
    "                latents = latents\n",
    "            )[\"images\"]\n",
    "\n",
    "        # create response\n",
    "        encoded_images = []\n",
    "        for image in generated_images:\n",
    "            buffered = BytesIO()\n",
    "            image.save(buffered, format=\"JPEG\")\n",
    "            encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "        # create response\n",
    "        return {\"generated_images\": encoded_images, \"seeds\": seeds or [seed]}\n",
    "\n",
    "    if mode == 'image2image' and init_image:\n",
    "        seed = seed or generator.seed()\n",
    "        # generators = [generator.manual_seed(seed)]*num_images_per_prompt\n",
    "        # run generation with parameters\n",
    "        init_image = base64.b64decode(init_image)\n",
    "        buffer = BytesIO(init_image)\n",
    "        init_image = Image.open(buffer).convert(\"RGB\")\n",
    "        init_image = init_image.resize((width, height))\n",
    "\n",
    "\n",
    "        generated_images = pipe['image2image'](\n",
    "            num_images_per_prompt=num_images_per_prompt,\n",
    "            prompt=prompt,\n",
    "            image=init_image,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            strength=strength,\n",
    "            negative_prompt=negative_prompt,\n",
    "            # negative_prompt=[negative_prompt]*num_images_per_prompt if negative_prompt else None,\n",
    "            # generator=generators,\n",
    "        )[\"images\"]\n",
    "\n",
    "        # create response\n",
    "        encoded_images = []\n",
    "        for image in generated_images:\n",
    "            buffered = BytesIO()\n",
    "            image.save(buffered, format=\"JPEG\")\n",
    "            encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "        # create response\n",
    "        return {\"generated_images\": encoded_images, \"seeds\": seeds or [seed]}\n",
    "\n",
    "    if mode == 'text2vector':\n",
    "        # tokenize the prompt\n",
    "        prompt_inputs = pipe['text2image'].tokenizer(\n",
    "            prompt, return_tensors='pt',\n",
    "            padding='max_length'\n",
    "        ).to(\"cuda\")\n",
    "        # create prompt encoding\n",
    "        prompt_embeds = pipe['text2image'].text_encoder(**prompt_inputs)\n",
    "        # extract CLIP embedding\n",
    "        prompt_embeds = prompt_embeds['pooler_output']\n",
    "\n",
    "        prompt_embeds = prompt_embeds.cpu().detach().numpy()\n",
    "\n",
    "        # Serialize the NumPy array to JSON\n",
    "        prompt_embeds = json.dumps(prompt_embeds.tolist())\n",
    "\n",
    "        return {\"generated_vector\": prompt_embeds}\n",
    "\n",
    "    return {\"error\": \"specify mode (text2image, text2vector, or image2image)\"}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6dd6072-9ef6-4a32-b93a-87f7067a1183",
   "metadata": {},
   "source": [
    "# Creation of the Hugging Face Model and deploy\n",
    "\n",
    "If you don't have a custom ECR image, you can change the variable `custom_ecr_image` to `aws_DLC_image`. Additionally, make sure to run the `write_requirements.txt` script to enable SageMaker to install the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb274c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# %%writefile code/requirements.txt\n",
    "# diffusers==0.11.1 \n",
    "# transformers==4.25.1 \n",
    "# scipy==1.9.3 \n",
    "# accelerate==0.15.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673db27-8c8e-4815-b6b3-afff123dac63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=model_uri,      # path to your model and script\n",
    "   image_uri=custom_ecr_image, # path to your private ecr image\n",
    "   entry_point = 'inference.py', #custom inference script\n",
    "   source_dir = \"./code/\",\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e03aefe",
   "metadata": {},
   "source": [
    "# Testing the Endpoint\n",
    "\n",
    "Please allow a few minutes for the endpoint to become live. Once it's ready, you can test the endpoint using either the predictor object or invoke the endpoint using boto3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fac6d59",
   "metadata": {},
   "source": [
    "### text2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70209253",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_per_prompt = 3\n",
    "prompt = \"lamb on a scooter, yellow color, high quality, highly detailed, elegant, sharp focus\"\n",
    "\n",
    "# Perform prediction\n",
    "response = predictor.predict(data={\n",
    "  \"inputs\": prompt,\n",
    "  \"mode\": \"text2image\",\n",
    "  \"num_images_per_prompt\": num_images_per_prompt,\n",
    "  }\n",
    ")\n",
    "\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "display_images(decoded_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17a38f9e",
   "metadata": {},
   "source": [
    "### image2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = Image.open(\"./sketch-mountains-input.jpeg\")\n",
    "buffered = BytesIO()\n",
    "init_image.save(buffered, format=\"JPEG\")\n",
    "init_image = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "# run prediction\n",
    "response = predictor.predict(data={\n",
    "  \"inputs\": \"A fantasy landscape, trending on artstation\",\n",
    "  \"mode\": \"image2image\",\n",
    "  \"num_images_per_prompt\": 1,\n",
    "    \"image\": init_image,\n",
    "  }\n",
    ")\n",
    "\n",
    "# decode images\n",
    "decoded_images = [decode_base64_image(image) for image in [init_image, response[\"generated_images\"][0]]]\n",
    "\n",
    "# visualize generation\n",
    "display_images(decoded_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45ff79c4",
   "metadata": {},
   "source": [
    "### Text2Vector\n",
    "\n",
    "If you wish to store the text vector, you can invoke this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e581b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_per_prompt = 3\n",
    "prompt = \"lamb on a scooter, yellow color, high quality, highly detailed, elegant, sharp focus\"\n",
    "\n",
    "# Perform prediction\n",
    "response = predictor.predict(data={\n",
    "  \"inputs\": prompt,\n",
    "  \"mode\": \"text2vector\"\n",
    "  }\n",
    ")\n",
    "\n",
    "response[\"generated_vector\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6c56536",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Remember to delete your endpoint to ensure that resources are not being unnecessarily consumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a79e2e-714a-464c-be54-96c60ade8fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
